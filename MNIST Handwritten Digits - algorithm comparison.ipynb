{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(image):\n",
    "    \"\"\"\n",
    "    This function receives an image and plots the digit. \n",
    "    \"\"\"\n",
    "    nameI = str(randint(1,299))+ \".png\"\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()\n",
    "    #plt.savefig(nameI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(train_x, train_y, test1_x, test1_y, test2_x, test2_y):\n",
    "\n",
    "    #Train and evaluate a feedforward network with a single hidden layer.\n",
    "    \n",
    "    model = Sequential([\n",
    "      Flatten(input_shape=(28, 28)),\n",
    "      Dense(512, activation='relu'),\n",
    "      Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(train_x, train_y, epochs=10)\n",
    "\n",
    "    print(\"Evaluating feedforward \")\n",
    "    model.evaluate(test1_x, test1_y)\n",
    "\n",
    "    print(\"Evaluating feedforward on shifted test data\")\n",
    "    model.evaluate(test2_x, test2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(train_x, train_y, test1_x, test1_y, test2_x, test2_y):\n",
    "    \n",
    "    #Train and evaluate a feedforward network with hidden layers.\n",
    "    \n",
    "    # Add a single \"channels\" dimension at the end\n",
    "    # allows for satisfying tensorflow neural networks structure that require the channels dimension\n",
    "    # to be added even though we are using black and white images so it is unimportant\n",
    "    \n",
    "    trn_x = train_x.reshape([-1, 28, 28, 1])\n",
    "    tst1_x = test1_x.reshape([-1, 28, 28, 1])\n",
    "    tst2_x = test2_x.reshape([-1, 28, 28, 1])\n",
    "\n",
    "    # First layer will need argument `input_shape=(28,28,1)`\n",
    "    model = Sequential([\n",
    "        Conv2D(32,(5,5)),\n",
    "        MaxPooling2D((2,2),(2,2)),\n",
    "        Conv2D(64,(5,5)),\n",
    "        MaxPooling2D((2,2),(1,1)),\n",
    "        Flatten(input_shape=(28,28,1)),\n",
    "        Dense(512,activation='relu'),\n",
    "        Dense(10,activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(trn_x, train_y, epochs=10)\n",
    "\n",
    "    print(\"Evaluating CNN \")\n",
    "    model.evaluate(tst1_x, test1_y)\n",
    "    print(\"Evaluating CNN on shifted test data\")\n",
    "    model.evaluate(tst2_x, test2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decenter(X,pad=2):\n",
    "    out = np.roll(X, 2, axis=1)\n",
    "    out = np.roll(X, 2, axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_theta(X, W, B):\n",
    "    \"\"\"\n",
    "    For a given matrix W and vector B, this function predicts the value\n",
    "    of each digit for each image of X. Here we assume that each column of X\n",
    "    is a flattened image. \n",
    "    \"\"\"\n",
    "    return W.dot(X) + B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l5GradDesc(images, labels, images_test, test_labels, images_test2, test_labels2):\n",
    "    images = images.reshape(images.shape[0],28*28)\n",
    "    images = images.T\n",
    "    \n",
    "    images_test = images_test.reshape(images_test.shape[0], 28*28)\n",
    "    images_test = images_test.T\n",
    "    \n",
    "    images_test2 = images_test2.reshape(images_test2.shape[0], 28*28)\n",
    "    images_test2 = images_test2.T\n",
    "    # Learning rate alpha, for controlling the step of gradient descent\n",
    "    alpha = 0.01\n",
    "\n",
    "    # Number of instances in the training set\n",
    "    m = images.shape[1]\n",
    "\n",
    "    # Matrix W initialized with zeros\n",
    "    W = np.zeros((10, 28*28))\n",
    "\n",
    "    # Matrix B also initialized with zeros\n",
    "    B = np.zeros((10,1))\n",
    "\n",
    "    # Creating Y matrix where each column is an one-hot vector\n",
    "    Y = np.zeros((10, m))\n",
    "    for index, value in enumerate(labels):\n",
    "        Y[value][index] = 1\n",
    "\n",
    "    # Performs 1000 iterations of gradient descent\n",
    "    # print(\"start W shape is \", W.shape)\n",
    "    # print(\"start B shape is \", B.shape)\n",
    "    for i in range(1000):\n",
    "        # Write here your implementation of gradient descent\n",
    "\n",
    "        temp = ((W.dot(images) + B - Y)).dot(np.transpose(images))\n",
    "        w_pderivativ = (1/m) * temp\n",
    "        b_pderivativ = (1/m) * (W.dot(images) + B - Y)\n",
    "        b_pderivative = []\n",
    "        for row in b_pderivativ:\n",
    "            n_row= sum(row)\n",
    "            b_pderivative.append(n_row)\n",
    "        b_pderivative = np.array(b_pderivative).reshape(10,1)\n",
    "\n",
    "        W = W - (alpha * w_pderivativ)\n",
    "        B = B - (alpha * b_pderivative)\n",
    "        \n",
    "    #make predictions for first test set\n",
    "    Y_hat = W.dot(images_test) + B\n",
    "\n",
    "    #one hot encode the results\n",
    "    results = []\n",
    "    for row in np.transpose(Y_hat):\n",
    "        results.append(np.argmax(row))\n",
    "\n",
    "    #get accuracy of the data based on the training results\n",
    "    accurate = 0\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == test_labels[i]:\n",
    "            accurate += 1\n",
    "    print(\"percentage accuracy is: \", accurate/len(results))\n",
    "    \n",
    "    \n",
    "    Y_hat2 = W.dot(images_test2) + B\n",
    "\n",
    "    #one hot encode the results\n",
    "    results = []\n",
    "    for row in np.transpose(Y_hat2):\n",
    "        results.append(np.argmax(row))\n",
    "\n",
    "    #get accuracy of the data based on the training results\n",
    "    accurate = 0\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == test_labels2[i]:\n",
    "            accurate += 1\n",
    "    print(\"percentage accuracy of shifted test data is: \", accurate/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    #change x_train and x_test data to float from uint8\n",
    "    x_train = x_train/255.0\n",
    "    x_test = x_test/255.0\n",
    "    \n",
    "    #use one hot encoding to represent the answers ie labels for the data\n",
    "    #both for training and testing\n",
    "    with tf.compat.v1.Session():\n",
    "        y_tran = tf.one_hot(y_train, 10).eval()\n",
    "        y_tst = tf.one_hot(y_test, 10).eval()\n",
    "    \n",
    "    \n",
    "    #shift the test data by 2 pixels to the bottom right\n",
    "    x_test2 = decenter(x_test, 2)\n",
    "    \n",
    "    num  = randint(256,456)\n",
    "    plot_digit(x_test[num])\n",
    "    plot_digit(x_test2[num])\n",
    "    print('Label: ', y_test[num])\n",
    "    \n",
    "    \n",
    "    num  = randint(256,456)\n",
    "    plot_digit(x_test[num])\n",
    "    plot_digit(x_test2[num])\n",
    "    print('Label: ', y_test[num])\n",
    "    #call classification algorithms    \n",
    "    \n",
    "#     Evaluate the 1 layer feed forward neural network model\n",
    "    feed_forward(x_train, y_tran, x_test, y_tst, x_test2, y_tst)\n",
    "#     Evaluate the convolutional neural network model\n",
    "    cnn(x_train, y_tran, x_test, y_tst, x_test2, y_tst)\n",
    "#     Evaluate the lab 5 code\n",
    "    l5GradDesc(x_train, y_train, x_test, y_test, x_test2, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
